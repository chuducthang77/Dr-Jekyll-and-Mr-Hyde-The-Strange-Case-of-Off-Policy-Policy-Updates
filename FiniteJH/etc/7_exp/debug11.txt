Number of states: 10
Number of actions: 2
Info about the experiment: The chain domain is designed to have multiple states where each state has two actions: Action 1 leads to an immediate reward, while action 2 leads to no reward but a better long-term reward. The optimal policy is always choosing action 2.
Run #11
-----------------------------------------------------------
-----------------------------------------------------------
Iteration 0
Discounting theory with old adv calculation: [0.0082, -0.0082, 0.00772, -0.00772, 0.00674, -0.00674, 0.00475, -0.00475, 0.00075, -0.00075, -0.00734, 0.00734, -0.02368, 0.02368, -0.0567, 0.0567, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5
 0.5 0.5]
The q-value with old adv calculation: [0.87660746 0.86020099 0.87660746 0.86117233 0.87660746 0.86313461
 0.87660746 0.86709883 0.87660746 0.87510735 0.87660746 0.89128619
 0.87660746 0.92397069 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [0.00456, -0.00456, 0.00429, -0.00429, 0.00374, -0.00374, 0.00264, -0.00264, 0.00042, -0.00042, -0.00408, 0.00408, -0.01316, 0.01316, -0.0315, 0.0315, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.8]
 [1.8]
 [1.8]
 [1.8]
 [1.8]
 [1.8]
 [1.8]
 [1.8]
 [1.8]
 [1.8]]
The policy with new adv calculation: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5
 0.5 0.5]
The q-value with new adv calculation: [0.87660746 0.86020099 0.87660746 0.86117233 0.87660746 0.86313461
 0.87660746 0.86709883 0.87660746 0.87510735 0.87660746 0.89128619
 0.87660746 0.92397069 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 500
Discounting theory with old adv calculation: [0.00041, -0.01433, 0.00604, -0.00878, 0.00612, -0.00711, 0.00451, -0.00474, 0.00049, -0.0005, -0.00785, 0.0077, -0.02457, 0.02382, -0.05773, 0.05566, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.97210553 0.02789447 0.59255959 0.40744041 0.53745422 0.46254578
 0.51259576 0.48740424 0.50082376 0.49917624 0.495098   0.504902
 0.49227449 0.50772551 0.49087243 0.50912757 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.86186135 0.87660746 0.86178212 0.87660746 0.86337533
 0.87660746 0.86735197 0.87660746 0.8756171  0.87660746 0.89216347
 0.87660746 0.92499534 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [0.00025, -0.91243, 0.00497, -0.00545, 0.00061, -0.00062, 0.00011, -0.00011, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.75630216e-03]
 [1.47756248e-01]
 [1.09305555e+00]
 [4.18659064e+00]
 [1.15559701e+01]
 [2.76089017e+01]
 [6.02992241e+01]
 [1.26612233e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99729254e-01 2.70745896e-04 5.23425117e-01 4.76574883e-01
 5.02771721e-01 4.97228279e-01 5.00510717e-01 4.99489283e-01
 5.00028986e-01 4.99971014e-01 4.99880216e-01 5.00119784e-01
 4.99823185e-01 5.00176815e-01 4.99798492e-01 5.00201508e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.86057816 0.87660746 0.86121305 0.87660746 0.86314223
 0.87660746 0.86710451 0.87660746 0.87511875 0.87660746 0.89130568
 0.87660746 0.92399331 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 1000
Discounting theory with old adv calculation: [0.0002, -0.01453, 0.00603, -0.00879, 0.00612, -0.00711, 0.00451, -0.00474, 0.00049, -0.00049, -0.00786, 0.0077, -0.02457, 0.02382, -0.05774, 0.05565, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.98620754 0.01379246 0.59330793 0.40669207 0.53773976 0.46226024
 0.51268811 0.48731189 0.50082852 0.49917148 0.49506093 0.50493907
 0.49221689 0.50778311 0.49080459 0.50919541 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.86187416 0.87660746 0.86178667 0.87660746 0.8633771
 0.87660746 0.86735388 0.87660746 0.87562097 0.87660746 0.89217006
 0.87660746 0.92500296 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [0.00012, -1.00575, 0.00508, -0.00559, 0.00062, -0.00063, 0.00011, -0.00011, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.59269220e-03]
 [1.44245788e-01]
 [1.08071720e+00]
 [4.16326325e+00]
 [1.15240328e+01]
 [2.75711895e+01]
 [6.02584200e+01]
 [1.26569790e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99882955e-01 1.17044511e-04 5.23993662e-01 4.76006338e-01
 5.02803359e-01 4.97196641e-01 5.00513578e-01 4.99486422e-01
 5.00029066e-01 4.99970934e-01 4.99880052e-01 5.00119948e-01
 4.99823065e-01 5.00176935e-01 4.99798425e-01 5.00201575e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.86058703 0.87660746 0.86121348 0.87660746 0.86314226
 0.87660746 0.86710452 0.87660746 0.87511875 0.87660746 0.89130569
 0.87660746 0.92399332 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 1500
Discounting theory with old adv calculation: [0.00013, -0.01459, 0.00602, -0.0088, 0.00611, -0.00712, 0.00451, -0.00474, 0.00049, -0.00049, -0.00786, 0.00771, -0.02458, 0.02382, -0.05774, 0.05565, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.99085969 0.00914031 0.59370122 0.40629878 0.53788975 0.46211025
 0.5127366  0.4872634  0.50083102 0.49916898 0.49504147 0.50495853
 0.49218664 0.50781336 0.49076897 0.50923103 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.8618809  0.87660746 0.86178906 0.87660746 0.86337803
 0.87660746 0.86735489 0.87660746 0.875623   0.87660746 0.89217352
 0.87660746 0.92500696 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [8e-05, -1.0586, 0.00514, -0.00567, 0.00062, -0.00063, 0.00011, -0.00011, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.51280292e-03]
 [1.42432501e-01]
 [1.07428731e+00]
 [4.15105366e+00]
 [1.15072809e+01]
 [2.75513874e+01]
 [6.02369831e+01]
 [1.26547487e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99927226e-01 7.27737831e-05 5.24298279e-01 4.75701721e-01
 5.02820134e-01 4.97179866e-01 5.00515089e-01 4.99484911e-01
 5.00029108e-01 4.99970892e-01 4.99879966e-01 5.00120034e-01
 4.99823002e-01 5.00176998e-01 4.99798389e-01 5.00201611e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.86059178 0.87660746 0.86121371 0.87660746 0.86314228
 0.87660746 0.86710452 0.87660746 0.87511876 0.87660746 0.89130569
 0.87660746 0.92399333 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 2000
Discounting theory with old adv calculation: [0.0001, -0.01462, 0.00602, -0.0088, 0.00611, -0.00712, 0.00451, -0.00474, 0.00049, -0.00049, -0.00786, 0.00771, -0.02458, 0.02382, -0.05775, 0.05565, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.9931694  0.0068306  0.59396463 0.40603537 0.53799018 0.46200982
 0.51276906 0.48723094 0.50083269 0.49916731 0.49502843 0.50497157
 0.49216639 0.50783361 0.49074512 0.50925488 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.8618854  0.87660746 0.86179066 0.87660746 0.86337865
 0.87660746 0.86735556 0.87660746 0.87562436 0.87660746 0.89217583
 0.87660746 0.92500963 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [6e-05, -1.09555, 0.00518, -0.00572, 0.00063, -0.00063, 0.00011, -0.00011, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.46151138e-03]
 [1.41230070e-01]
 [1.07000175e+00]
 [4.14289552e+00]
 [1.14960738e+01]
 [2.75381316e+01]
 [6.02226287e+01]
 [1.26532550e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99947806e-01 5.21941685e-05 5.24504578e-01 4.75495422e-01
 5.02831427e-01 4.97168573e-01 5.00516103e-01 4.99483897e-01
 5.00029137e-01 4.99970863e-01 4.99879908e-01 5.00120092e-01
 4.99822960e-01 5.00177040e-01 4.99798366e-01 5.00201634e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.860595   0.87660746 0.86121387 0.87660746 0.86314229
 0.87660746 0.86710452 0.87660746 0.87511876 0.87660746 0.8913057
 0.87660746 0.92399333 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 2500
Discounting theory with old adv calculation: [8e-05, -0.01464, 0.00601, -0.0088, 0.00611, -0.00712, 0.00451, -0.00474, 0.00049, -0.00049, -0.00786, 0.00771, -0.02458, 0.02382, -0.05775, 0.05564, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.99454864 0.00545136 0.59416113 0.40583887 0.53806508 0.46193492
 0.51279327 0.48720673 0.50083393 0.49916607 0.49501871 0.50498129
 0.49215128 0.50784872 0.49072733 0.50927267 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.86188877 0.87660746 0.86179186 0.87660746 0.86337911
 0.87660746 0.86735606 0.87660746 0.87562537 0.87660746 0.89217756
 0.87660746 0.92501163 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [5e-05, -1.12397, 0.00521, -0.00575, 0.00063, -0.00063, 0.00011, -0.00011, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.42436505e-03]
 [1.40339306e-01]
 [1.06681566e+00]
 [4.13681973e+00]
 [1.14877201e+01]
 [2.75282466e+01]
 [6.02119220e+01]
 [1.26521407e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99959579e-01 4.04212992e-05 5.24659676e-01 4.75340324e-01
 5.02839881e-01 4.97160119e-01 5.00516861e-01 4.99483139e-01
 5.00029158e-01 4.99970842e-01 4.99879865e-01 5.00120135e-01
 4.99822928e-01 5.00177072e-01 4.99798348e-01 5.00201652e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.86059742 0.87660746 0.86121398 0.87660746 0.86314229
 0.87660746 0.86710452 0.87660746 0.87511876 0.87660746 0.8913057
 0.87660746 0.92399333 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 3000
Discounting theory with old adv calculation: [7e-05, -0.01465, 0.00601, -0.0088, 0.00611, -0.00712, 0.00451, -0.00474, 0.00049, -0.00049, -0.00786, 0.00771, -0.02458, 0.02382, -0.05775, 0.05564, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.99546501 0.00453499 0.59431706 0.40568294 0.53812451 0.46187549
 0.51281247 0.48718753 0.50083491 0.49916509 0.495011   0.504989
 0.4921393  0.5078607  0.49071322 0.50928678 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.86189143 0.87660746 0.8617928  0.87660746 0.86337948
 0.87660746 0.86735646 0.87660746 0.87562617 0.87660746 0.89217893
 0.87660746 0.92501321 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [4e-05, -1.14704, 0.00524, -0.00579, 0.00063, -0.00064, 0.00011, -0.00012, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.39555031e-03]
 [1.39636236e-01]
 [1.06429404e+00]
 [4.13200460e+00]
 [1.14810953e+01]
 [2.75204048e+01]
 [6.02034271e+01]
 [1.26512566e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99967157e-01 3.28429153e-05 5.24783486e-01 4.75216514e-01
 5.02846608e-01 4.97153392e-01 5.00517463e-01 4.99482537e-01
 5.00029175e-01 4.99970825e-01 4.99879831e-01 5.00120169e-01
 4.99822903e-01 5.00177097e-01 4.99798334e-01 5.00201666e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.86059935 0.87660746 0.86121408 0.87660746 0.8631423
 0.87660746 0.86710452 0.87660746 0.87511876 0.87660746 0.8913057
 0.87660746 0.92399333 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 3500
Discounting theory with old adv calculation: [6e-05, -0.01466, 0.00601, -0.00881, 0.00611, -0.00712, 0.00451, -0.00474, 0.00049, -0.00049, -0.00786, 0.00771, -0.02458, 0.02382, -0.05775, 0.05564, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.99611788 0.00388212 0.59444587 0.40555413 0.53817359 0.46182641
 0.51282833 0.48717167 0.50083572 0.49916428 0.49500463 0.50499537
 0.4921294  0.5078706  0.49070157 0.50929843 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.86189364 0.87660746 0.86179359 0.87660746 0.86337979
 0.87660746 0.86735679 0.87660746 0.87562684 0.87660746 0.89218006
 0.87660746 0.92501452 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [3e-05, -1.16647, 0.00526, -0.00581, 0.00063, -0.00064, 0.00011, -0.00012, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.37218039e-03]
 [1.39057964e-01]
 [1.06221544e+00]
 [4.12803111e+00]
 [1.14756255e+01]
 [2.75139285e+01]
 [6.01964105e+01]
 [1.26505263e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99972423e-01 2.75765604e-05 5.24886254e-01 4.75113746e-01
 5.02852178e-01 4.97147822e-01 5.00517961e-01 4.99482039e-01
 5.00029189e-01 4.99970811e-01 4.99879803e-01 5.00120197e-01
 4.99822883e-01 5.00177117e-01 4.99798322e-01 5.00201678e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.86060095 0.87660746 0.86121415 0.87660746 0.8631423
 0.87660746 0.86710452 0.87660746 0.87511876 0.87660746 0.8913057
 0.87660746 0.92399333 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 4000
Discounting theory with old adv calculation: [5e-05, -0.01466, 0.00601, -0.00881, 0.00611, -0.00712, 0.00451, -0.00474, 0.00049, -0.00049, -0.00786, 0.00771, -0.02459, 0.02382, -0.05775, 0.05564, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.99660656 0.00339344 0.59455532 0.40544468 0.5382153  0.4617847
 0.5128418  0.4871582  0.50083641 0.49916359 0.49499922 0.50500078
 0.49212099 0.50787901 0.49069167 0.50930833 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.86189551 0.87660746 0.86179425 0.87660746 0.86338004
 0.87660746 0.86735707 0.87660746 0.8756274  0.87660746 0.89218103
 0.87660746 0.92501563 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [3e-05, -1.18324, 0.00528, -0.00583, 0.00063, -0.00064, 0.00012, -0.00012, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.35262454e-03]
 [1.38568354e-01]
 [1.06045228e+00]
 [4.12465758e+00]
 [1.14709796e+01]
 [2.75084264e+01]
 [6.01904486e+01]
 [1.26499057e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99976285e-01 2.37146989e-05 5.24973934e-01 4.75026066e-01
 5.02856919e-01 4.97143081e-01 5.00518385e-01 4.99481615e-01
 5.00029200e-01 4.99970800e-01 4.99879778e-01 5.00120222e-01
 4.99822865e-01 5.00177135e-01 4.99798312e-01 5.00201688e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.86060232 0.87660746 0.86121422 0.87660746 0.86314231
 0.87660746 0.86710452 0.87660746 0.87511876 0.87660746 0.8913057
 0.87660746 0.92399333 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 4500
Discounting theory with old adv calculation: [4e-05, -0.01467, 0.006, -0.00881, 0.00611, -0.00712, 0.00451, -0.00474, 0.00049, -0.00049, -0.00787, 0.00771, -0.02459, 0.02382, -0.05775, 0.05564, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.99698603 0.00301397 0.5946503  0.4053497  0.53825148 0.46174852
 0.51285349 0.48714651 0.50083701 0.49916299 0.49499452 0.50500548
 0.4921137  0.5078863  0.49068308 0.50931692 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.86189713 0.87660746 0.86179483 0.87660746 0.86338027
 0.87660746 0.86735731 0.87660746 0.87562789 0.87660746 0.89218186
 0.87660746 0.9250166  0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [2e-05, -1.19799, 0.00529, -0.00585, 0.00063, -0.00064, 0.00012, -0.00012, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.33587687e-03]
 [1.38144805e-01]
 [1.05892459e+00]
 [4.12173231e+00]
 [1.14669494e+01]
 [2.75036526e+01]
 [6.01852755e+01]
 [1.26493672e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99979232e-01 2.07675179e-05 5.25050283e-01 4.74949717e-01
 5.02861039e-01 4.97138961e-01 5.00518753e-01 4.99481247e-01
 5.00029211e-01 4.99970789e-01 4.99879758e-01 5.00120242e-01
 4.99822850e-01 5.00177150e-01 4.99798304e-01 5.00201696e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.86060351 0.87660746 0.86121428 0.87660746 0.86314231
 0.87660746 0.86710452 0.87660746 0.87511877 0.87660746 0.8913057
 0.87660746 0.92399333 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 5000
Discounting theory with old adv calculation: [4e-05, -0.01467, 0.006, -0.00881, 0.00611, -0.00712, 0.00451, -0.00474, 0.00049, -0.00049, -0.00787, 0.00771, -0.02459, 0.02382, -0.05775, 0.05564, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.99728921 0.00271079 0.59473406 0.40526594 0.53828339 0.46171661
 0.5128638  0.4871362  0.50083754 0.49916246 0.49499038 0.50500962
 0.49210727 0.50789273 0.4906755  0.5093245  0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.86189856 0.87660746 0.86179533 0.87660746 0.86338047
 0.87660746 0.86735752 0.87660746 0.87562832 0.87660746 0.8921826
 0.87660746 0.92501745 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [2e-05, -1.21115, 0.00531, -0.00587, 0.00063, -0.00064, 0.00012, -0.00012, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.32127579e-03]
 [1.37772276e-01]
 [1.05757906e+00]
 [4.11915410e+00]
 [1.14633962e+01]
 [2.74994430e+01]
 [6.01807134e+01]
 [1.26488923e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99981552e-01 1.84480630e-05 5.25117822e-01 4.74882178e-01
 5.02864679e-01 4.97135321e-01 5.00519077e-01 4.99480923e-01
 5.00029220e-01 4.99970780e-01 4.99879739e-01 5.00120261e-01
 4.99822837e-01 5.00177163e-01 4.99798296e-01 5.00201704e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.86060456 0.87660746 0.86121433 0.87660746 0.86314232
 0.87660746 0.86710452 0.87660746 0.87511877 0.87660746 0.8913057
 0.87660746 0.92399334 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 5500
Discounting theory with old adv calculation: [4e-05, -0.01467, 0.006, -0.00881, 0.00611, -0.00712, 0.00451, -0.00474, 0.00049, -0.00049, -0.00787, 0.00771, -0.02459, 0.02382, -0.05775, 0.05564, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.99753699 0.00246301 0.5948089  0.4051911  0.5383119  0.4616881
 0.51287301 0.48712699 0.50083801 0.49916199 0.49498668 0.50501332
 0.49210152 0.50789848 0.49066874 0.50933126 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.86189984 0.87660746 0.86179579 0.87660746 0.86338064
 0.87660746 0.86735772 0.87660746 0.87562871 0.87660746 0.89218325
 0.87660746 0.92501821 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [2e-05, -1.22303, 0.00532, -0.00588, 0.00063, -0.00064, 0.00012, -0.00012, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.30836439e-03]
 [1.37440271e-01]
 [1.05637843e+00]
 [4.11685212e+00]
 [1.14602227e+01]
 [2.74956828e+01]
 [6.01766380e+01]
 [1.26484680e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99983423e-01 1.65773896e-05 5.25178322e-01 4.74821678e-01
 5.02867934e-01 4.97132066e-01 5.00519368e-01 4.99480632e-01
 5.00029228e-01 4.99970772e-01 4.99879723e-01 5.00120277e-01
 4.99822825e-01 5.00177175e-01 4.99798289e-01 5.00201711e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.8606055  0.87660746 0.86121437 0.87660746 0.86314232
 0.87660746 0.86710453 0.87660746 0.87511877 0.87660746 0.89130571
 0.87660746 0.92399334 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 6000
Discounting theory with old adv calculation: [3e-05, -0.01467, 0.006, -0.00881, 0.00611, -0.00712, 0.00451, -0.00474, 0.00049, -0.00049, -0.00787, 0.00771, -0.02459, 0.02382, -0.05776, 0.05564, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.99774328 0.00225672 0.59487646 0.40512354 0.53833763 0.46166237
 0.51288132 0.48711868 0.50083843 0.49916157 0.49498334 0.50501666
 0.49209633 0.50790367 0.49066263 0.50933737 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.861901   0.87660746 0.8617962  0.87660746 0.8633808
 0.87660746 0.86735789 0.87660746 0.87562906 0.87660746 0.89218385
 0.87660746 0.92501889 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [2e-05, -1.23386, 0.00533, -0.0059, 0.00063, -0.00064, 0.00012, -0.00012, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.29681469e-03]
 [1.37141188e-01]
 [1.05529566e+00]
 [4.11477499e+00]
 [1.14573584e+01]
 [2.74922886e+01]
 [6.01729590e+01]
 [1.26480850e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99984962e-01 1.50382779e-05 5.25233072e-01 4.74766928e-01
 5.02870876e-01 4.97129124e-01 5.00519630e-01 4.99480370e-01
 5.00029235e-01 4.99970765e-01 4.99879708e-01 5.00120292e-01
 4.99822814e-01 5.00177186e-01 4.99798283e-01 5.00201717e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.86060636 0.87660746 0.86121441 0.87660746 0.86314232
 0.87660746 0.86710453 0.87660746 0.87511877 0.87660746 0.89130571
 0.87660746 0.92399334 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 6500
Discounting theory with old adv calculation: [3e-05, -0.01467, 0.006, -0.00881, 0.00611, -0.00712, 0.00451, -0.00474, 0.00049, -0.00049, -0.00787, 0.00771, -0.02459, 0.02382, -0.05776, 0.05564, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.99791769 0.00208231 0.59493798 0.40506202 0.53836107 0.46163893
 0.51288889 0.48711111 0.50083882 0.49916118 0.4949803  0.5050197
 0.49209161 0.50790839 0.49065707 0.50934293 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.86190205 0.87660746 0.86179657 0.87660746 0.86338095
 0.87660746 0.86735804 0.87660746 0.87562937 0.87660746 0.89218439
 0.87660746 0.92501952 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [2e-05, -1.2438, 0.00534, -0.00591, 0.00063, -0.00064, 0.00012, -0.00012, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.28638376e-03]
 [1.36869351e-01]
 [1.05431054e+00]
 [4.11288427e+00]
 [1.14547506e+01]
 [2.74891978e+01]
 [6.01696087e+01]
 [1.26477362e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99986249e-01 1.37508203e-05 5.25283042e-01 4.74716958e-01
 5.02873558e-01 4.97126442e-01 5.00519869e-01 4.99480131e-01
 5.00029242e-01 4.99970758e-01 4.99879694e-01 5.00120306e-01
 4.99822804e-01 5.00177196e-01 4.99798278e-01 5.00201722e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.86060714 0.87660746 0.86121445 0.87660746 0.86314232
 0.87660746 0.86710453 0.87660746 0.87511877 0.87660746 0.89130571
 0.87660746 0.92399334 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 7000
Discounting theory with old adv calculation: [3e-05, -0.01468, 0.006, -0.00881, 0.00611, -0.00712, 0.00451, -0.00474, 0.00049, -0.00049, -0.00787, 0.00771, -0.02459, 0.02382, -0.05776, 0.05564, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.99806708 0.00193292 0.59499442 0.40500558 0.53838257 0.46161743
 0.51289583 0.48710417 0.50083917 0.49916083 0.49497751 0.50502249
 0.49208727 0.50791273 0.49065196 0.50934804 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.86190301 0.87660746 0.86179691 0.87660746 0.86338108
 0.87660746 0.86735819 0.87660746 0.87562966 0.87660746 0.89218488
 0.87660746 0.92502009 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [2e-05, -1.253, 0.00535, -0.00592, 0.00064, -0.00064, 0.00012, -0.00012, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.27688698e-03]
 [1.36620413e-01]
 [1.05340758e+00]
 [4.11115046e+00]
 [1.14523586e+01]
 [2.74863626e+01]
 [6.01665353e+01]
 [1.26474162e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99987341e-01 1.26587217e-05 5.25328976e-01 4.74671024e-01
 5.02876020e-01 4.97123980e-01 5.00520088e-01 4.99479912e-01
 5.00029248e-01 4.99970752e-01 4.99879682e-01 5.00120318e-01
 4.99822795e-01 5.00177205e-01 4.99798272e-01 5.00201728e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.86060785 0.87660746 0.86121448 0.87660746 0.86314233
 0.87660746 0.86710453 0.87660746 0.87511877 0.87660746 0.89130571
 0.87660746 0.92399334 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 7500
Discounting theory with old adv calculation: [3e-05, -0.01468, 0.006, -0.00881, 0.00611, -0.00712, 0.00451, -0.00474, 0.00049, -0.00049, -0.00787, 0.00771, -0.02459, 0.02382, -0.05776, 0.05564, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.99819648 0.00180352 0.59504653 0.40495347 0.53840241 0.46159759
 0.51290224 0.48709776 0.5008395  0.4991605  0.49497494 0.50502506
 0.49208327 0.50791673 0.49064725 0.50935275 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.86190391 0.87660746 0.86179723 0.87660746 0.8633812
 0.87660746 0.86735832 0.87660746 0.87562993 0.87660746 0.89218534
 0.87660746 0.92502062 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [1e-05, -1.26155, 0.00536, -0.00593, 0.00064, -0.00064, 0.00012, -0.00012, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.26818095e-03]
 [1.36390979e-01]
 [1.05257466e+00]
 [4.10955048e+00]
 [1.14501508e+01]
 [2.74837454e+01]
 [6.01636981e+01]
 [1.26471208e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99988279e-01 1.17212086e-05 5.25371459e-01 4.74628541e-01
 5.02878296e-01 4.97121704e-01 5.00520290e-01 4.99479710e-01
 5.00029253e-01 4.99970747e-01 4.99879670e-01 5.00120330e-01
 4.99822786e-01 5.00177214e-01 4.99798268e-01 5.00201732e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.86060851 0.87660746 0.86121451 0.87660746 0.86314233
 0.87660746 0.86710453 0.87660746 0.87511877 0.87660746 0.89130571
 0.87660746 0.92399334 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 8000
Discounting theory with old adv calculation: [2e-05, -0.01468, 0.006, -0.00881, 0.0061, -0.00712, 0.00451, -0.00474, 0.00049, -0.00049, -0.00787, 0.00771, -0.02459, 0.02382, -0.05776, 0.05564, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.99830964 0.00169036 0.5950949  0.4049051  0.53842083 0.46157917
 0.51290819 0.48709181 0.50083981 0.49916019 0.49497255 0.50502745
 0.49207956 0.50792044 0.49064288 0.50935712 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.86190473 0.87660746 0.86179752 0.87660746 0.86338132
 0.87660746 0.86735845 0.87660746 0.87563018 0.87660746 0.89218576
 0.87660746 0.92502111 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [1e-05, -1.26954, 0.00536, -0.00594, 0.00064, -0.00064, 0.00012, -0.00012, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.26015220e-03]
 [1.36178341e-01]
 [1.05180212e+00]
 [4.10806590e+00]
 [1.14481019e+01]
 [2.74813163e+01]
 [6.01610646e+01]
 [1.26468467e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99989092e-01 1.09080443e-05 5.25410960e-01 4.74589040e-01
 5.02880409e-01 4.97119591e-01 5.00520478e-01 4.99479522e-01
 5.00029259e-01 4.99970741e-01 4.99879660e-01 5.00120340e-01
 4.99822779e-01 5.00177221e-01 4.99798263e-01 5.00201737e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.86060913 0.87660746 0.86121454 0.87660746 0.86314233
 0.87660746 0.86710453 0.87660746 0.87511877 0.87660746 0.89130571
 0.87660746 0.92399334 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 8500
Discounting theory with old adv calculation: [2e-05, -0.01468, 0.006, -0.00881, 0.0061, -0.00712, 0.00451, -0.00474, 0.00049, -0.00049, -0.00787, 0.00771, -0.02459, 0.02382, -0.05776, 0.05563, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.99840943 0.00159057 0.59514001 0.40485999 0.53843801 0.46156199
 0.51291374 0.48708626 0.50084009 0.49915991 0.49497032 0.50502968
 0.4920761  0.5079239  0.4906388  0.5093612  0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.8619055  0.87660746 0.8617978  0.87660746 0.86338142
 0.87660746 0.86735856 0.87660746 0.87563041 0.87660746 0.89218616
 0.87660746 0.92502157 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [1e-05, -1.27704, 0.00537, -0.00595, 0.00064, -0.00064, 0.00012, -0.00012, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.25270950e-03]
 [1.35980313e-01]
 [1.05108214e+00]
 [4.10668184e+00]
 [1.14461913e+01]
 [2.74790511e+01]
 [6.01586087e+01]
 [1.26465910e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99989804e-01 1.01963446e-05 5.25447857e-01 4.74552143e-01
 5.02882382e-01 4.97117618e-01 5.00520654e-01 4.99479346e-01
 5.00029263e-01 4.99970737e-01 4.99879650e-01 5.00120350e-01
 4.99822771e-01 5.00177229e-01 4.99798259e-01 5.00201741e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.8606097  0.87660746 0.86121457 0.87660746 0.86314233
 0.87660746 0.86710453 0.87660746 0.87511877 0.87660746 0.89130571
 0.87660746 0.92399334 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 9000
Discounting theory with old adv calculation: [2e-05, -0.01468, 0.006, -0.00881, 0.0061, -0.00712, 0.0045, -0.00474, 0.00049, -0.00049, -0.00787, 0.00771, -0.02459, 0.02382, -0.05776, 0.05563, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.9984981  0.0015019  0.59518225 0.40481775 0.5384541  0.4615459
 0.51291893 0.48708107 0.50084035 0.49915965 0.49496823 0.50503177
 0.49207286 0.50792714 0.49063499 0.50936501 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.86190623 0.87660746 0.86179805 0.87660746 0.86338152
 0.87660746 0.86735867 0.87660746 0.87563063 0.87660746 0.89218653
 0.87660746 0.925022   0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [1e-05, -1.2841, 0.00538, -0.00596, 0.00064, -0.00064, 0.00012, -0.00012, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.24577847e-03]
 [1.35795103e-01]
 [1.05040830e+00]
 [4.10538605e+00]
 [1.14444024e+01]
 [2.74769298e+01]
 [6.01563088e+01]
 [1.26463515e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99990432e-01 9.56847956e-06 5.25482463e-01 4.74517537e-01
 5.02884231e-01 4.97115769e-01 5.00520818e-01 4.99479182e-01
 5.00029268e-01 4.99970732e-01 4.99879641e-01 5.00120359e-01
 4.99822765e-01 5.00177235e-01 4.99798255e-01 5.00201745e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.86061024 0.87660746 0.8612146  0.87660746 0.86314233
 0.87660746 0.86710453 0.87660746 0.87511877 0.87660746 0.89130571
 0.87660746 0.92399334 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 9500
Discounting theory with old adv calculation: [2e-05, -0.01468, 0.00599, -0.00881, 0.0061, -0.00712, 0.0045, -0.00474, 0.00049, -0.00049, -0.00787, 0.00771, -0.02459, 0.02382, -0.05776, 0.05563, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.99857741 0.00142259 0.59522196 0.40477804 0.53846922 0.46153078
 0.51292382 0.48707618 0.5008406  0.4991594  0.49496627 0.50503373
 0.49206981 0.50793019 0.4906314  0.5093686  0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.8619069  0.87660746 0.86179829 0.87660746 0.86338162
 0.87660746 0.86735877 0.87660746 0.87563084 0.87660746 0.89218688
 0.87660746 0.9250224  0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting theory with new adv calculation: [1e-05, -1.29078, 0.00539, -0.00596, 0.00064, -0.00065, 0.00012, -0.00012, 1e-05, -1e-05, -3e-05, 3e-05, -4e-05, 4e-05, -4e-05, 4e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.23929772e-03]
 [1.35621223e-01]
 [1.04977528e+00]
 [4.10416837e+00]
 [1.14427210e+01]
 [2.74749359e+01]
 [6.01541470e+01]
 [1.26461264e+02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99990989e-01 9.01065306e-06 5.25515038e-01 4.74484962e-01
 5.02885969e-01 4.97114031e-01 5.00520973e-01 4.99479027e-01
 5.00029272e-01 4.99970728e-01 4.99879632e-01 5.00120368e-01
 4.99822758e-01 5.00177242e-01 4.99798252e-01 5.00201748e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.86061075 0.87660746 0.86121462 0.87660746 0.86314233
 0.87660746 0.86710453 0.87660746 0.87511877 0.87660746 0.89130571
 0.87660746 0.92399334 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
Algorithm name: theory: $d_{\pi_t,\gamma}$
Number of times the advantage are difference: 0
The first time the adv functions are different: 0
The time the adv functions are same again : 0
-----------------------------------------------------------
Iteration 0
Discounting jh with old adv calculation: [0.0082, -0.0082, 0.00772, -0.00772, 0.00674, -0.00674, 0.00475, -0.00475, 0.00075, -0.00075, -0.00734, 0.00734, -0.02368, 0.02368, -0.0567, 0.0567, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [0 0 0 0 0 1 1 1 0 0]
The policy with old adv calculation: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5
 0.5 0.5]
The q-value with old adv calculation: [0.87660746 0.86020099 0.87660746 0.86117233 0.87660746 0.86313461
 0.87660746 0.86709883 0.87660746 0.87510735 0.87660746 0.89128619
 0.87660746 0.92397069 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [0.00456, -0.00456, 0.00429, -0.00429, 0.00374, -0.00374, 0.00264, -0.00264, 0.00042, -0.00042, -0.00408, 0.00408, -0.01316, 0.01316, -0.0315, 0.0315, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 0 0 0 0 1 1 1 0 0]
The temperature value is: [[1.8]
 [1.8]
 [1.8]
 [1.8]
 [1.8]
 [1.8]
 [1.8]
 [1.8]
 [1.8]
 [1.8]]
The policy with new adv calculation: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5
 0.5 0.5]
The q-value with new adv calculation: [0.87660746 0.86020099 0.87660746 0.86117233 0.87660746 0.86313461
 0.87660746 0.86709883 0.87660746 0.87510735 0.87660746 0.89128619
 0.87660746 0.92397069 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 500
Discounting jh with old adv calculation: [-0.00319, 0.01413, -0.02635, 0.01033, -0.0459, 0.00542, -0.06069, 0.00379, -0.07399, 0.00305, -0.08667, 0.00262, -0.09904, 0.00233, -0.11126, 0.00213, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [0.81604081 0.18395919 0.28159385 0.71840615 0.10553287 0.89446713
 0.05884663 0.94115337 0.03954293 0.96045707 0.0292973  0.9707027
 0.02302736 0.97697264 0.01882641 0.98117359 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.89392775 0.87660746 0.91328568 0.87660746 0.92792665
 0.87660746 0.94109449 0.87660746 0.95364686 0.87660746 0.96589556
 0.87660746 0.97798657 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [0.00043, -0.84254, -6e-05, 6e-05, -0.024, 0.01665, -0.02129, 0.01531, -0.3181, 0.01576, -0.53392, 0.00421, -0.55152, 0.00373, -0.56369, 0.00342, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [0 1 1 1 1 1 1 1 0 0]
The temperature value is: [[5.01025361e-04]
 [7.18926856e+00]
 [7.54951593e-02]
 [1.87205617e-01]
 [2.45412212e-02]
 [1.71590724e-02]
 [1.85170565e-02]
 [1.99946000e-02]
 [1.80000000e+00]
 [1.80000000e+00]]
The policy with new adv calculation: [9.99493123e-01 5.06877164e-04 4.99712958e-01 5.00287042e-01
 4.09550324e-01 5.90449676e-01 4.18385404e-01 5.81614596e-01
 4.72122696e-02 9.52787730e-01 7.82058196e-03 9.92179418e-01
 6.71146667e-03 9.93288533e-01 6.03550227e-03 9.93964498e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.87238396 0.87660746 0.88577912 0.87660746 0.90729411
 0.87660746 0.94512575 0.87660746 0.95854074 0.87660746 0.9689451
 0.87660746 0.97942246 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: False
-----------------------------------------------------------
Iteration 1000
Discounting jh with old adv calculation: [-0.03834, 0.00163, -0.04923, 0.0012, -0.0598, 0.00103, -0.0703, 0.00093, -0.08081, 0.00087, -0.09135, 0.00082, -0.10196, 0.00079, -0.11263, 0.00076, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [0.04089962 0.95910038 0.02387594 0.97612406 0.01693312 0.98306688
 0.01306385 0.98693615 0.01060005 0.98939995 0.0088936  0.9911064
 0.00764227 0.99235773 0.0066859  0.9933141  0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.91658294 0.87660746 0.92704561 0.87660746 0.93743979
 0.87660746 0.94783944 0.87660746 0.9582793  0.87660746 0.96877863
 0.87660746 0.97934945 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-0.6579, 0.00174, -0.65753, 0.00174, -0.68626, 0.00141, -0.68439, 0.00143, -0.70381, 0.00124, -0.73284, 0.00099, -0.73661, 0.00096, -0.73933, 0.00094, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.00685121]
 [0.00828932]
 [0.00933399]
 [0.01076729]
 [0.01185608]
 [0.0127298 ]
 [0.01401208]
 [0.01531771]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [0.00263361 0.99736639 0.00264241 0.99735759 0.00204765 0.99795235
 0.00208203 0.99791797 0.00175174 0.99824826 0.00135239 0.99864761
 0.00130773 0.99869227 0.0012764  0.9987236  0.5        0.5
 0.5        0.5       ]
The q-value with new adv calculation: [0.87660746 0.92180079 0.87660746 0.93125632 0.87660746 0.94079438
 0.87660746 0.95045109 0.87660746 0.96019804 0.87660746 0.97002334
 0.87660746 0.97995671 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 1500
Discounting jh with old adv calculation: [-0.04212, 0.00076, -0.05217, 0.00056, -0.06212, 0.00052, -0.07212, 0.00049, -0.0822, 0.00047, -0.09236, 0.00046, -0.10261, 0.00045, -0.11295, 0.00044, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [0.01779671 0.98220329 0.01067524 0.98932476 0.00828789 0.99171211
 0.00676417 0.99323583 0.0057063  0.9942937  0.00492822 0.99507178
 0.00433168 0.99566832 0.00385972 0.99614028 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.91948565 0.87660746 0.92933627 0.87660746 0.93924262
 0.87660746 0.94922109 0.87660746 0.95928094 0.87660746 0.96942809
 0.87660746 0.97966671 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-0.78414, 0.00067, -0.78355, 0.00067, -0.79491, 0.00062, -0.79369, 0.00062, -0.8021, 0.00058, -0.81624, 0.00052, -0.81792, 0.00052, -0.81908, 0.00051, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.00582829]
 [0.00702675]
 [0.00811625]
 [0.00933279]
 [0.01043948]
 [0.01145465]
 [0.01263654]
 [0.01383531]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [8.55182654e-04 9.99144817e-01 8.59756177e-04 9.99140244e-01
 7.76666609e-04 9.99223333e-01 7.85160481e-04 9.99214840e-01
 7.28224475e-04 9.99271776e-01 6.41625389e-04 9.99358375e-01
 6.32027669e-04 9.99367972e-01 6.25524472e-04 9.99374476e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.92234881 0.87660746 0.93171284 0.87660746 0.94117423
 0.87660746 0.95073924 0.87660746 0.96040369 0.87660746 0.97016477
 0.87660746 0.98002978 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 2000
Discounting jh with old adv calculation: [-0.04344, 0.00049, -0.05323, 0.00036, -0.06299, 0.00034, -0.07283, 0.00033, -0.08275, 0.00032, -0.09277, 0.00032, -0.10288, 0.00031, -0.11309, 0.00031, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [0.01114503 0.98885497 0.00678825 0.99321175 0.00543939 0.99456061
 0.00453462 0.99546538 0.00388493 0.99611507 0.00339528 0.99660472
 0.00301284 0.99698716 0.0027058  0.9972942  0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.92053579 0.87660746 0.93019792 0.87660746 0.93993834
 0.87660746 0.9497644  0.87660746 0.95968072 0.87660746 0.96969051
 0.87660746 0.97979625 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-0.84695, 0.00041, -0.84633, 0.00041, -0.85318, 0.00039, -0.85217, 0.0004, -0.85734, 0.00038, -0.86649, 0.00035, -0.86743, 0.00035, -0.86801, 0.00035, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.00541603]
 [0.00652367]
 [0.00757771]
 [0.00870594]
 [0.00977771]
 [0.01079834]
 [0.01192091]
 [0.0130582 ]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [4.87236376e-04 9.99512764e-01 4.89967186e-04 9.99510033e-01
 4.60776733e-04 9.99539223e-01 4.64973092e-04 9.99535027e-01
 4.43902594e-04 9.99556097e-01 4.08898576e-04 9.99591101e-01
 4.05484962e-04 9.99594515e-01 4.03365211e-04 9.99596635e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.92250092 0.87660746 0.93184618 0.87660746 0.94128857
 0.87660746 0.95083104 0.87660746 0.96047263 0.87660746 0.97021264
 0.87660746 0.98005472 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 2500
Discounting jh with old adv calculation: [-0.04411, 0.00036, -0.05377, 0.00027, -0.06344, 0.00026, -0.0732, 0.00025, -0.08304, 0.00024, -0.09298, 0.00024, -0.10302, 0.00024, -0.11316, 0.00024, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [0.00806371 0.99193629 0.00495695 0.99504305 0.00403681 0.99596319
 0.00340333 0.99659667 0.00294012 0.99705988 0.00258633 0.99741367
 0.00230716 0.99769284 0.00208119 0.99791881 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.92107617 0.87660746 0.93064784 0.87660746 0.94030546
 0.87660746 0.95005346 0.87660746 0.95989484 0.87660746 0.96983185
 0.87660746 0.97986637 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-0.8889, 0.0003, -0.88827, 0.0003, -0.89306, 0.00029, -0.89215, 0.00029, -0.89579, 0.00028, -0.90246, 0.00027, -0.90301, 0.00027, -0.90331, 0.00027, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.00516911]
 [0.00622361]
 [0.00724633]
 [0.00832185]
 [0.00936302]
 [0.01037174]
 [0.01145376]
 [0.01254938]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [3.34424897e-04 9.99665575e-01 3.36319577e-04 9.99663680e-01
 3.22156091e-04 9.99677844e-01 3.24798881e-04 9.99675201e-01
 3.14377615e-04 9.99685622e-01 2.96087588e-04 9.99703912e-01
 2.94622308e-04 9.99705378e-01 2.93852204e-04 9.99706148e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.92257098 0.87660746 0.93190848 0.87660746 0.94134255
 0.87660746 0.95087518 0.87660746 0.96050636 0.87660746 0.97023617
 0.87660746 0.98006701 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 3000
Discounting jh with old adv calculation: [-0.04452, 0.00028, -0.0541, 0.00021, -0.06372, 0.0002, -0.07342, 0.0002, -0.08322, 0.0002, -0.09312, 0.00019, -0.10311, 0.00019, -0.1132, 0.00019, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [0.00630081 0.99369919 0.00389716 0.99610284 0.0032053  0.9967947
 0.00272122 0.99727878 0.0023632  0.9976368  0.00208744 0.99791256
 0.0018684  0.9981316  0.00169017 0.99830983 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.92140495 0.87660746 0.93092375 0.87660746 0.94053192
 0.87660746 0.95023259 0.87660746 0.96002804 0.87660746 0.96992008
 0.87660746 0.97991026 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-0.92038, 0.00023, -0.91975, 0.00023, -0.92337, 0.00023, -0.92252, 0.00023, -0.92526, 0.00022, -0.93045, 0.00021, -0.93077, 0.00021, -0.93089, 0.00021, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.00499705]
 [0.00601498]
 [0.0070124 ]
 [0.00805132]
 [0.00906759]
 [0.01006189]
 [0.01111367]
 [0.01217833]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [2.52081928e-04 9.99747918e-01 2.53513287e-04 9.99746487e-01
 2.45404043e-04 9.99754596e-01 2.47284079e-04 9.99752716e-01
 2.41278471e-04 9.99758722e-01 2.30278303e-04 9.99769722e-01
 2.29613663e-04 9.99770386e-01 2.29378244e-04 9.99770622e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.92261084 0.87660746 0.93194417 0.87660746 0.94137364
 0.87660746 0.95090083 0.87660746 0.96052614 0.87660746 0.97024999
 0.87660746 0.98007425 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 3500
Discounting jh with old adv calculation: [-0.04479, 0.00023, -0.05433, 0.00017, -0.06391, 0.00017, -0.07358, 0.00017, -0.08335, 0.00016, -0.09321, 0.00016, -0.10317, 0.00016, -0.11323, 0.00016, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [0.00516353 0.99483647 0.00320785 0.99679215 0.00265608 0.99734392
 0.00226574 0.99773426 0.00197476 0.99802524 0.00174932 0.99825068
 0.00156944 0.99843056 0.00142253 0.99857747 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.92162589 0.87660746 0.93111008 0.87660746 0.94068543
 0.87660746 0.95035439 0.87660746 0.96011884 0.87660746 0.96998035
 0.87660746 0.97994031 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-0.94556, 0.00019, -0.94493, 0.00019, -0.94779, 0.00019, -0.94699, 0.00019, -0.94914, 0.00018, -0.95335, 0.00018, -0.95352, 0.00018, -0.95351, 0.00018, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.00486691]
 [0.0058574 ]
 [0.00683413]
 [0.00784545]
 [0.00884121]
 [0.00982159]
 [0.01084954]
 [0.01188987]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [2.01047496e-04 9.99798953e-01 2.02188479e-04 9.99797812e-01
 1.97055082e-04 9.99802945e-01 1.98493107e-04 9.99801507e-01
 1.94691444e-04 9.99805309e-01 1.87461588e-04 9.99812538e-01
 1.87179455e-04 9.99812821e-01 1.87186808e-04 9.99812813e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.92263638 0.87660746 0.93196713 0.87660746 0.94139371
 0.87660746 0.95091748 0.87660746 0.96053905 0.87660746 0.97025902
 0.87660746 0.98007899 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 4000
Discounting jh with old adv calculation: [-0.04498, 0.0002, -0.05449, 0.00015, -0.06404, 0.00015, -0.07369, 0.00014, -0.08344, 0.00014, -0.09328, 0.00014, -0.10321, 0.00014, -0.11325, 0.00014, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [0.00437065 0.99562935 0.00272431 0.99727569 0.00226665 0.99773335
 0.00194028 0.99805972 0.00169558 0.99830442 0.00150518 0.99849482
 0.00135273 0.99864727 0.0012279  0.9987721  0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.92178448 0.87660746 0.93124428 0.87660746 0.94079628
 0.87660746 0.95044254 0.87660746 0.96018468 0.87660746 0.97002412
 0.87660746 0.97996216 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-0.96654, 0.00016, -0.96591, 0.00016, -0.96824, 0.00016, -0.96746, 0.00016, -0.9692, 0.00016, -0.97271, 0.00015, -0.97277, 0.00015, -0.97268, 0.00015, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.00476328]
 [0.00573205]
 [0.00669146]
 [0.00768086]
 [0.00865938]
 [0.00962699]
 [0.01063544]
 [0.01165587]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [1.66510303e-04 9.99833490e-01 1.67453854e-04 9.99832546e-01
 1.63978581e-04 9.99836021e-01 1.65132379e-04 9.99834868e-01
 1.62569283e-04 9.99837431e-01 1.57518514e-04 9.99842481e-01
 1.57437060e-04 9.99842563e-01 1.57563145e-04 9.99842437e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.92265406 0.87660746 0.93198307 0.87660746 0.94140767
 0.87660746 0.95092911 0.87660746 0.9605481  0.87660746 0.97026536
 0.87660746 0.98008231 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 4500
Discounting jh with old adv calculation: [-0.04512, 0.00017, -0.05461, 0.00013, -0.06415, 0.00013, -0.07378, 0.00013, -0.0835, 0.00012, -0.09333, 0.00012, -0.10325, 0.00012, -0.11327, 0.00012, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [0.003787   0.996213   0.00236666 0.99763334 0.00197632 0.99802368
 0.00169625 0.99830375 0.00148533 0.99851467 0.00132067 0.99867933
 0.00118849 0.99881151 0.00108002 0.99891998 0.5        0.5
 0.5        0.5       ]
The q-value with old adv calculation: [0.87660746 0.92190381 0.87660746 0.93134552 0.87660746 0.94088007
 0.87660746 0.95050927 0.87660746 0.96023459 0.87660746 0.97005734
 0.87660746 0.97997876 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-0.98451, 0.00014, -0.98388, 0.00014, -0.98582, 0.00014, -0.98506, 0.00014, -0.9865, 0.00014, -0.98949, 0.00013, -0.98946, 0.00013, -0.98931, 0.00013, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.00467778]
 [0.00562869]
 [0.00657334]
 [0.00754466]
 [0.00850844]
 [0.00946448]
 [0.01045651]
 [0.01146022]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [1.41679225e-04 9.99858321e-01 1.42480582e-04 9.99857519e-01
 1.40012669e-04 9.99859987e-01 1.40970190e-04 9.99859030e-01
 1.39163024e-04 9.99860837e-01 1.35474237e-04 9.99864526e-01
 1.35504528e-04 9.99864495e-01 1.35690415e-04 9.99864310e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.92266699 0.87660746 0.93199475 0.87660746 0.94141791
 0.87660746 0.95093766 0.87660746 0.96055478 0.87660746 0.97027004
 0.87660746 0.98008477 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 5000
Discounting jh with old adv calculation: [-0.04524, 0.00015, -0.0547, 0.00011, -0.06423, 0.00011, -0.07384, 0.00011, -0.08356, 0.00011, -0.09337, 0.00011, -0.10327, 0.00011, -0.11328, 0.00011, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [3.33977766e-03 9.96660222e-01 2.09154267e-03 9.97908457e-01
 1.75162357e-03 9.98248376e-01 1.50654263e-03 9.98493457e-01
 1.32133318e-03 9.98678667e-01 1.17635371e-03 9.98823646e-01
 1.05973715e-03 9.98940263e-01 9.63877874e-04 9.99036122e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with old adv calculation: [0.87660746 0.92199684 0.87660746 0.93142459 0.87660746 0.94094562
 0.87660746 0.95056154 0.87660746 0.96027372 0.87660746 0.97008341
 0.87660746 0.9799918  0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-1.00022, 0.00012, -0.99959, 0.00012, -1.00123, 0.00012, -1.00049, 0.00012, -1.00169, 0.00012, -1.00428, 0.00012, -1.00419, 0.00012, -1.00399, 0.00012, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.00460538]
 [0.00554121]
 [0.00647305]
 [0.0074291 ]
 [0.00838003]
 [0.00932562]
 [0.01030354]
 [0.01129289]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [1.23018810e-04 9.99876981e-01 1.23713277e-04 9.99876287e-01
 1.21897360e-04 9.99878103e-01 1.22712127e-04 9.99877288e-01
 1.21395213e-04 9.99878605e-01 1.18608715e-04 9.99881391e-01
 1.18703480e-04 9.99881297e-01 1.18918953e-04 9.99881081e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.92267683 0.87660746 0.93200365 0.87660746 0.94142573
 0.87660746 0.9509442  0.87660746 0.96055989 0.87660746 0.97027362
 0.87660746 0.98008665 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 5500
Discounting jh with old adv calculation: [-0.04533, 0.00014, -0.05478, 0.0001, -0.06429, 0.0001, -0.0739, 0.0001, -0.0836, 0.0001, -0.0934, 0.0001, -0.1033, 0.0001, -0.11329, 0.0001, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [2.98634571e-03 9.97013654e-01 1.87342891e-03 9.98126571e-01
 1.57261350e-03 9.98427387e-01 1.35487368e-03 9.98645126e-01
 1.18985702e-03 9.98810143e-01 1.06040628e-03 9.98939594e-01
 9.56104655e-04 9.99043895e-01 8.70251320e-04 9.99129749e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with old adv calculation: [0.87660746 0.92207139 0.87660746 0.93148805 0.87660746 0.94099829
 0.87660746 0.95060357 0.87660746 0.96030522 0.87660746 0.97010442
 0.87660746 0.98000231 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-1.01417, 0.00011, -1.01355, 0.00011, -1.01495, 0.00011, -1.01423, 0.00011, -1.01524, 0.00011, -1.0175, 0.00011, -1.01736, 0.00011, -1.01712, 0.00011, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.00454284]
 [0.00546568]
 [0.00638624]
 [0.00732911]
 [0.00826873]
 [0.00920483]
 [0.01017042]
 [0.01114723]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [1.08513838e-04 9.99891486e-01 1.09125260e-04 9.99890875e-01
 1.07752232e-04 9.99892248e-01 1.08459006e-04 9.99891541e-01
 1.07475188e-04 9.99892525e-01 1.05313938e-04 9.99894686e-01
 1.05446470e-04 9.99894554e-01 1.05675202e-04 9.99894325e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.92268455 0.87660746 0.93201064 0.87660746 0.94143187
 0.87660746 0.95094935 0.87660746 0.96056392 0.87660746 0.97027645
 0.87660746 0.98008814 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 6000
Discounting jh with old adv calculation: [-0.0454, 0.00012, -0.05484, 9e-05, -0.06434, 9e-05, -0.07394, 9e-05, -0.08363, 9e-05, -0.09342, 9e-05, -0.10331, 9e-05, -0.1133, 9e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [2.70011128e-03 9.97299889e-01 1.69631201e-03 9.98303688e-01
 1.42667252e-03 9.98573327e-01 1.23086388e-03 9.98769136e-01
 1.08211706e-03 9.98917883e-01 9.65220876e-04 9.99034779e-01
 8.70902450e-04 9.99129098e-01 7.93178331e-04 9.99206822e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with old adv calculation: [0.87660746 0.92213245 0.87660746 0.9315401  0.87660746 0.94104152
 0.87660746 0.95063812 0.87660746 0.96033112 0.87660746 0.9701217
 0.87660746 0.98001096 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-1.02672, 0.0001, -1.0261, 0.0001, -1.02731, 0.0001, -1.0266, 0.0001, -1.02746, 0.0001, -1.02945, 0.0001, -1.02927, 0.0001, -1.029, 0.0001, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.00448796]
 [0.00539944]
 [0.00630997]
 [0.00724128]
 [0.0081708 ]
 [0.00909826]
 [0.01005293]
 [0.01101864]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [9.69345677e-05 9.99903065e-01 9.74797540e-05 9.99902520e-01
 9.64192555e-05 9.99903581e-01 9.70417710e-05 9.99902958e-01
 9.62927430e-05 9.99903707e-01 9.45805590e-05 9.99905419e-01
 9.47350629e-05 9.99905265e-01 9.49679256e-05 9.99905032e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.92269076 0.87660746 0.93201627 0.87660746 0.94143683
 0.87660746 0.95095351 0.87660746 0.96056718 0.87660746 0.97027874
 0.87660746 0.98008934 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 6500
Discounting jh with old adv calculation: [-0.04546, 0.00011, -0.05489, 9e-05, -0.06439, 8e-05, -0.07398, 8e-05, -0.08366, 8e-05, -0.09345, 8e-05, -0.10333, 8e-05, -0.11331, 8e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [2.46364199e-03 9.97536358e-01 1.54965537e-03 9.98450345e-01
 1.30543055e-03 9.98694569e-01 1.12759189e-03 9.98872408e-01
 9.92226426e-04 9.99007774e-01 8.85685564e-04 9.99114314e-01
 7.99620254e-04 9.99200380e-01 7.28629008e-04 9.99271371e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with old adv calculation: [0.87660746 0.92218338 0.87660746 0.93158356 0.87660746 0.94107766
 0.87660746 0.950667   0.87660746 0.96035279 0.87660746 0.97013616
 0.87660746 0.98001821 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-1.03812, 9e-05, -1.0375, 9e-05, -1.03856, 9e-05, -1.03785, 9e-05, -1.03859, 9e-05, -1.04036, 9e-05, -1.04015, 9e-05, -1.03985, 9e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.00443921]
 [0.00534059]
 [0.00624211]
 [0.00716317]
 [0.0080836 ]
 [0.00900313]
 [0.00994803]
 [0.01090381]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [8.74895275e-05 9.99912510e-01 8.79807471e-05 9.99912019e-01
 8.71476809e-05 9.99912852e-01 8.77028044e-05 9.99912297e-01
 8.71242653e-05 9.99912876e-01 8.57441554e-05 9.99914256e-01
 8.59109658e-05 9.99914089e-01 8.61427606e-05 9.99913857e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.92269586 0.87660746 0.9320209  0.87660746 0.9414409
 0.87660746 0.95095693 0.87660746 0.96056987 0.87660746 0.97028063
 0.87660746 0.98009033 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 7000
Discounting jh with old adv calculation: [-0.04552, 0.0001, -0.05493, 8e-05, -0.06442, 8e-05, -0.07401, 8e-05, -0.08369, 8e-05, -0.09346, 8e-05, -0.10334, 8e-05, -0.11332, 8e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [2.26504096e-03 9.97734959e-01 1.42624216e-03 9.98573758e-01
 1.20311869e-03 9.98796881e-01 1.04026531e-03 9.98959735e-01
 9.16094492e-04 9.99083906e-01 8.18237989e-04 9.99181762e-01
 7.39107497e-04 9.99260893e-01 6.73782614e-04 9.99326217e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with old adv calculation: [0.87660746 0.92222651 0.87660746 0.93162039 0.87660746 0.9411083
 0.87660746 0.95069151 0.87660746 0.96037119 0.87660746 0.97014845
 0.87660746 0.98002436 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-1.04856, 8e-05, -1.04794, 8e-05, -1.04887, 8e-05, -1.04817, 8e-05, -1.0488, 8e-05, -1.05039, 8e-05, -1.05014, 8e-05, -1.04982, 8e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.00439544]
 [0.00528778]
 [0.00618112]
 [0.00709298]
 [0.00800515]
 [0.0089174 ]
 [0.00985347]
 [0.01080027]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [7.96470541e-05 9.99920353e-01 8.00935190e-05 9.99919906e-01
 7.94302092e-05 9.99920570e-01 7.99303204e-05 9.99920070e-01
 7.94786469e-05 9.99920521e-01 7.83501183e-05 9.99921650e-01
 7.85231693e-05 9.99921477e-01 7.87509326e-05 9.99921249e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.92270012 0.87660746 0.93202476 0.87660746 0.94144431
 0.87660746 0.95095979 0.87660746 0.96057212 0.87660746 0.9702822
 0.87660746 0.98009116 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 7500
Discounting jh with old adv calculation: [-0.04556, 0.0001, -0.05497, 7e-05, -0.06446, 7e-05, -0.07403, 7e-05, -0.08371, 7e-05, -0.09348, 7e-05, -0.10335, 7e-05, -0.11332, 7e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [2.09591501e-03 9.97904085e-01 1.32096486e-03 9.98679035e-01
 1.11563251e-03 9.98884367e-01 9.65461231e-04 9.99034539e-01
 8.50790793e-04 9.99149209e-01 7.60319932e-04 9.99239680e-01
 6.87097091e-04 9.99312903e-01 6.26605897e-04 9.99373394e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with old adv calculation: [0.87660746 0.92226349 0.87660746 0.931652   0.87660746 0.94113461
 0.87660746 0.95071257 0.87660746 0.960387   0.87660746 0.97015901
 0.87660746 0.98002966 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-1.0582, 8e-05, -1.05758, 8e-05, -1.05839, 8e-05, -1.0577, 8e-05, -1.05824, 8e-05, -1.05967, 8e-05, -1.0594, 8e-05, -1.05906, 8e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.0043558 ]
 [0.00523995]
 [0.00612583]
 [0.00702936]
 [0.007934  ]
 [0.0088395 ]
 [0.00976752]
 [0.01070616]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [7.30372283e-05 9.99926963e-01 7.34460210e-05 9.99926554e-01
 7.29121373e-05 9.99927088e-01 7.33665699e-05 9.99926633e-01
 7.30112534e-05 9.99926989e-01 7.20772570e-05 9.99927923e-01
 7.22526754e-05 9.99927747e-01 7.24747537e-05 9.99927525e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.92270373 0.87660746 0.93202804 0.87660746 0.94144719
 0.87660746 0.95096221 0.87660746 0.96057402 0.87660746 0.97028354
 0.87660746 0.98009186 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 8000
Discounting jh with old adv calculation: [-0.0456, 9e-05, -0.055, 7e-05, -0.06448, 7e-05, -0.07406, 7e-05, -0.08373, 7e-05, -0.09349, 7e-05, -0.10336, 7e-05, -0.11333, 7e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [1.95017532e-03 9.98049825e-01 1.23010801e-03 9.98769892e-01
 1.03997273e-03 9.98960027e-01 9.00670062e-04 9.99099330e-01
 7.94161220e-04 9.99205839e-01 7.10046986e-04 9.99289953e-01
 6.41916178e-04 9.99358084e-01 5.85596317e-04 9.99414404e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with old adv calculation: [0.87660746 0.92229556 0.87660746 0.93167942 0.87660746 0.94115745
 0.87660746 0.95073085 0.87660746 0.96040074 0.87660746 0.97016819
 0.87660746 0.98003426 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-1.06714, 7e-05, -1.06652, 7e-05, -1.06723, 7e-05, -1.06655, 7e-05, -1.06701, 7e-05, -1.0683, 7e-05, -1.06801, 7e-05, -1.06765, 7e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.00431962]
 [0.00519632]
 [0.00607534]
 [0.00697128]
 [0.00786898]
 [0.00876822]
 [0.00968887]
 [0.01062003]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [6.73949861e-05 9.99932605e-01 6.77716627e-05 9.99932228e-01
 6.73382504e-05 9.99932662e-01 6.77542026e-05 9.99932246e-01
 6.74733507e-05 9.99932527e-01 6.66924216e-05 9.99933308e-01
 6.68677101e-05 9.99933132e-01 6.70832343e-05 9.99932917e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.92270682 0.87660746 0.93203085 0.87660746 0.94144967
 0.87660746 0.9509643  0.87660746 0.96057566 0.87660746 0.97028469
 0.87660746 0.98009247 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 8500
Discounting jh with old adv calculation: [-0.04563, 8e-05, -0.05503, 6e-05, -0.06451, 6e-05, -0.07408, 6e-05, -0.08374, 6e-05, -0.09351, 6e-05, -0.10337, 6e-05, -0.11333, 6e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [1.82329869e-03 9.98176701e-01 1.15090470e-03 9.98849095e-01
 9.73897048e-04 9.99026103e-01 8.44010157e-04 9.99155990e-01
 7.44587047e-04 9.99255413e-01 6.66000532e-04 9.99333999e-01
 6.02303495e-04 9.99397697e-01 5.49619565e-04 9.99450380e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with old adv calculation: [0.87660746 0.92232362 0.87660746 0.93170344 0.87660746 0.94117747
 0.87660746 0.95074688 0.87660746 0.96041279 0.87660746 0.97017624
 0.87660746 0.9800383  0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-1.07547, 7e-05, -1.07486, 7e-05, -1.07548, 7e-05, -1.0748, 7e-05, -1.0752, 7e-05, -1.07637, 7e-05, -1.07606, 7e-05, -1.07569, 7e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.0042864 ]
 [0.00515626]
 [0.00602894]
 [0.00691791]
 [0.0078092 ]
 [0.0087026 ]
 [0.00961646]
 [0.01054072]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [6.25255935e-05 9.99937474e-01 6.28745882e-05 9.99937125e-01
 6.25203853e-05 9.99937480e-01 6.29035168e-05 9.99937096e-01
 6.26810704e-05 9.99937319e-01 6.20224114e-05 9.99937978e-01
 6.21959569e-05 9.99937804e-01 6.24045343e-05 9.99937595e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.9227095  0.87660746 0.93203328 0.87660746 0.94145181
 0.87660746 0.9509661  0.87660746 0.96057708 0.87660746 0.97028569
 0.87660746 0.98009299 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 9000
Discounting jh with old adv calculation: [-0.04566, 8e-05, -0.05506, 6e-05, -0.06453, 6e-05, -0.07409, 6e-05, -0.08376, 6e-05, -0.09352, 6e-05, -0.10338, 6e-05, -0.11333, 6e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [1.71185544e-03 9.98288145e-01 1.08125234e-03 9.98918748e-01
 9.15695682e-04 9.99084304e-01 7.94043121e-04 9.99205957e-01
 7.00828431e-04 9.99299172e-01 6.27092269e-04 9.99372908e-01
 5.67290175e-04 9.99432710e-01 5.17803312e-04 9.99482197e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with old adv calculation: [0.87660746 0.9223484  0.87660746 0.93172464 0.87660746 0.94119514
 0.87660746 0.95076105 0.87660746 0.96042344 0.87660746 0.97018336
 0.87660746 0.98004187 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-1.08329, 6e-05, -1.08267, 6e-05, -1.08322, 6e-05, -1.08255, 6e-05, -1.08288, 6e-05, -1.08395, 6e-05, -1.08362, 6e-05, -1.08324, 6e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.00425573]
 [0.00511927]
 [0.00598608]
 [0.0068686 ]
 [0.00775394]
 [0.00864188]
 [0.00954945]
 [0.01046732]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [5.82828786e-05 9.99941717e-01 5.86077842e-05 9.99941392e-01
 5.83168699e-05 9.99941683e-01 5.86717054e-05 9.99941328e-01
 5.84956580e-05 9.99941504e-01 5.79359607e-05 9.99942064e-01
 5.81067296e-05 9.99941893e-01 5.83082587e-05 9.99941692e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.92271184 0.87660746 0.93203541 0.87660746 0.94145369
 0.87660746 0.95096768 0.87660746 0.96057833 0.87660746 0.97028657
 0.87660746 0.98009345 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
-----------------------------------------------------------
Iteration 9500
Discounting jh with old adv calculation: [-0.04569, 7e-05, -0.05508, 6e-05, -0.06455, 6e-05, -0.07411, 6e-05, -0.08377, 6e-05, -0.09353, 6e-05, -0.10338, 6e-05, -0.11334, 6e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with old adv calculation: [1 1 1 1 1 1 1 1 0 0]
The policy with old adv calculation: [1.61319825e-03 9.98386802e-01 1.01952481e-03 9.98980475e-01
 8.64042287e-04 9.99135958e-01 7.49650635e-04 9.99250349e-01
 6.61919747e-04 9.99338080e-01 5.92473404e-04 9.99407527e-01
 5.36119690e-04 9.99463880e-01 4.89465725e-04 9.99510534e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with old adv calculation: [0.87660746 0.92237042 0.87660746 0.9317435  0.87660746 0.94121088
 0.87660746 0.95077365 0.87660746 0.96043291 0.87660746 0.9701897
 0.87660746 0.98004505 0.87660746 0.99       1.         1.
 0.         0.        ]
Discounting jh with new adv calculation: [-1.09063, 6e-05, -1.09002, 6e-05, -1.0905, 6e-05, -1.08983, 6e-05, -1.09012, 6e-05, -1.09109, 6e-05, -1.09075, 6e-05, -1.09035, 6e-05, 0.0, 0.0, 0.0, 0.0]
The better action at a given state with new adv calculation: [1 1 1 1 1 1 1 1 0 0]
The temperature value is: [[0.00422726]
 [0.00508495]
 [0.00594627]
 [0.00682283]
 [0.00770261]
 [0.00858543]
 [0.00948713]
 [0.01039906]
 [1.8       ]
 [1.8       ]]
The policy with new adv calculation: [5.45550539e-05 9.99945445e-01 5.48588193e-05 9.99945141e-01
 5.46190676e-05 9.99945381e-01 5.49492772e-05 9.99945051e-01
 5.48105017e-05 9.99945189e-01 5.43318324e-05 9.99945668e-01
 5.44991764e-05 9.99945501e-01 5.46937330e-05 9.99945306e-01
 5.00000000e-01 5.00000000e-01 5.00000000e-01 5.00000000e-01]
The q-value with new adv calculation: [0.87660746 0.9227139  0.87660746 0.93203728 0.87660746 0.94145534
 0.87660746 0.95096907 0.87660746 0.96057943 0.87660746 0.97028734
 0.87660746 0.98009386 0.87660746 0.99       1.         1.
 0.         0.        ]
Is better action same for both adv calculation: True
Algorithm name: $p_t=0.5$
Number of times the advantage are difference: 1
The first time the adv functions are different: 500
The time the adv functions are same again : 9500
